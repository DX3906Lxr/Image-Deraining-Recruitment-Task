# 任务二
## 一.代码截图
![alt text](<img/截屏2025-10-15 21.11.16.png>) 
![alt text](<img/截屏2025-10-15 21.11.21.png>) 
![alt text](<img/截屏2025-10-15 21.11.26.png>) 
![alt text](<img/截屏2025-10-15 21.11.45.png>) 
![alt text](<img/截屏2025-10-15 21.11.50.png>)
## 二.运行结果



## 三.思考：为什么 DerainNet 要先下采样后上采样？ 下采样、上采样是什么？什么是 Concat？
>我感觉这个DerainNet模型就是在ResNet基础上再运用了多尺度特征融合    
关于多尺度特征融合的好处，如下图所示，我在part1的任务三中已经阐述过，这里就不再赘述，    
而是具体来看看其实的实现     

>![alt text](<img/截屏2025-10-12 16.34.19.png>)

### 三层残差嵌套😱
![alt text](<img/截屏2025-10-12 15.34.58.png>)
其实不难发现，这个DerainNet比之前的baseline网络多了一层残差的嵌套    
也就是多了红色的那根残差线    
其实还是残差的基本思想    
因为可能有些尺度的有些特征，人家直接一层卷积就学得很好了     
你现在非要人家去通过那个八层卷积     
那肯定不好呀    
当然了，它如果“跳”八次，理论上一样能保持原样，但这样肯定还是不如直接“跳”一次
### 下采样：最大池化而非卷积
>最大池化和卷积都能下采样，为什么这里的DerainNet用最大池化?🤔    

下图是二者的大致区别   
![alt text](<img/截屏2025-10-12 14.41.43.png>)   
也就是对于图像分类，要的是强语义、抽象特征（不在意位置）所以卷积下采样
而对于图像去雨，我们希望的是在下采样时，空间细节、结构保持，MaxPooling更合适   
具体来说就是     
卷积下采样带参数，会在卷积过程中混合和平滑特征    
这对分类是好事（更抽象）   
但对去雨这种“重建原图”的任务，是坏事（细节丢失）
而 MaxPooling 只保留强响应，不带权平均，不模糊结构
这样下采样后的特征仍然能保留清晰的边缘和亮度信息，
有利于后续上采样时“还原”出干净细节     
而在残差网络中是我们想要“学习”到什么是雨丝，所以用卷积
### 上采样：可学习的上采样
上采样 + 卷积 + 激活 + 卷积
不仅放大尺寸，还要让模型自己学会如何在放大后补细节、调整纹理    
如果只是最近邻，双线性插值等上采样
它们“放大”了图像，但没有能力“修复”或“补出”丢失的信息    
比如下采样时很多高频细节（纹理、雨丝边缘）已经丢失     
单纯的插值无法恢复这些细节    
所以最终图像会模糊、失真     
然后使用激活函数（LeakyReLU）
提供非线性，使模型能“有选择地”增强重要特征    
同时卷积也再一步增大感受野
### 融合
通过不同尺度的下采样，然后层层卷积，最后再恢复到原输入的大小合并在一起为融合做准备，concat好像就是单纯的在第一个维度也就是通道维度上进行拼接，好像没啥可讲的     
### 分两次上采样与下采样
不一次性地缩小或放大两倍
让信息压缩与恢复过程尽可能地不丢失
