# 基础问题
我们应该让模型学习什么？是直接让模型学会从有雨图像到无雨图像的端到端映射（直接学习），还是让模型只专注于学习雨层，然后从原图像中减去它（残差学习）？
## 残差学习与残差网络
本题的“残差思想”其实体现在两个地方
- 一个是不直接端到端的直接学习，而是学习目标图减去原图的残差“雨层”
- 另一个是从原图到“雨层”的网络是采用的是残差网络，即ResNet

这两个“残差”当然都是“残差思想”，也就是对有利于目标实现的思想上是高度统一的，但是不妨先分开阐述，而后再串联起来
首先，必须要回答“残差”比端到端的“直接学习“的优势在哪里？

### 1.端到端的两点坏处
### 1.1“信号消失”
关于”信号消失”，不妨分别从正向和反向传播的角度来阐述
#### 正向传播
如果要用端到端，显然，需要很多的层，来先提取局部特征，再全局特再输出整张图
而图片的大部分其实是不需要更改的，也就是，要改变的“雨层”这一部分信息，本身只占整幅图像极小的比例，是一种弱信号
以及它的高频性
高频就是快速变化的部分：边缘、纹理、细线、噪声，具体就是“雨层”的雨丝、边缘细节、纹理线条
而网络在端到端正向传播过程中，主要特征流被主导于背景（强信号）
所以雨层的特征在卷积层逐层传递时，会被稀释，甚至消失
#### 反向传播
也是因为输出和输入太相似，差异极小，即稀疏性
所以关于目标函数的梯度本身就小，梯度在反向传播中又被层层网络稀释，最终在前层趋近于0，也就不更更新了，也就是“信号消失”
或者说得到的梯度不足以去适应高频部分的“快速变化”

### 1.2“信息退化”
刚才是讲到对于高频信号的“信号消失”，现在来讲讲对于低频信号的“信号退化”
#### 正向传播
对于一些东西，或者说绝大部分东西其实我们是希望保留的，但对于直接层与层直接“堆叠”的卷积网络，这些信息在正向传播的过程中其实是没办法很好地保留的，比如原本连续、柔和的背景结构被模糊化甚至完全丢失
不过具体为什么会这样，我就不做详细说明了，反正就是卷积网络的自身结构所导致的
#### 反向传播
反向传播就更容易理解了，因为这些内容我们是希望不变的，但却有可能在反向传播的过程中被“误更新”


### 2.两层残差的嵌套
#### 2.1任务层面的图像残差
正是由于如前所述的缺点，我们不直接学最终结果，而是学最终结果与原始输入图片的残差
即，y=x+f（x），x是原图，f（x）是“雨层”
（更严格来说应该是“雨层”的相反数，或者是有个负号，因为本题是“相减”，而不是相加）
这其实可以看作是一种“任务”层面的“残差”，即这是“图像”与“图像”的残差
#### 2.2结构层面的特征残差
完成了图像与图像的残差，现在我们更深入进入原图到“雨层”的网络模型，去探究“特征”间的残差
刚才所讲的端到端的“信号消失”的问题，对于原图到“雨层”的模型依旧存在
对于这个我们想学到的稀疏性，高频性雨层的特征，同样按照残差的思想，
即，y=x+f（x），f（x）是我们要学习的高频特征，x就是低频背景特征
我们在低频背景信息的基础上再去单独学习雨层特征
只不过最后，我们只输出“雨层”f（x），而对于“x”就不输出了

### 3.残差好处的多角度理解
#### 角度一
如图所示
![alt text](<img/截屏2025-10-10 10.58.36.png>)
对于原图到“雨层”，“整个”原图就相当于那条弯弯绕绕的红色曲线，而低频背景及就像那条“直线”，而雨层特征就是那些一个又一个的“弯”
而对于任务层面，同样，“整个”原图就相当于那条弯弯绕绕的红色曲线
而直线是我们的目标，也就是“无雨图”，而那些“弯”，就是“雨层”
>我们在直线的基础上去学习那些“弯”，比直接去学习那些“弯”要容易地多

#### 角度二
对于之前所讲的“信息退化”
残差网络可以很好地对不做变化的部分进行保留，因为等于说y=x+f（x）中的x可以直接越过f（x）进行恒等输出
![alt text](<img/截屏2025-10-10 12.29.20.png>)
这也就引出它的另一个优点了，就是即使加深层，也不会使得结果变坏
这正是因为残差网络能保留“之前”的结构
或者说深层残差网络的最优解肯定包含了浅层残差网络的最优解
所以学习的结果理论上不会比浅层的差

#### 角度三
下图正是具象化的展示，直接加深可能会使得越学越偏，真正要学的“高频”不但没学到，连“基本盘”都丢了
![alt text](<img/截屏2025-10-10 12.25.32.png>)

***
# 附加问题
## 问题一
>雨丝这一物体，在外表上表现出的线性特征，其实也存在于其他物体中（如条纹、纹理等）。在面对这种情况时，模型如何分辨谁是雨丝？
***
如果就是最简单的残差网络，不考虑引入注意力机制等，那就是靠统计差异+上下文语义
### 1.统计差异
就是说，虽然很像，不过总归还是不一样的，如下图所示
![alt text](<img/截屏2025-10-10 13.39.30.png>)
卷积核会自动学习这些差异

### 2.上下文语义
先来说说具体是如何形成的所谓上下文语义
#### 2.1局部特征
能识别图片中的一些简单的纹理和条纹等简单特征
这时的感受野很小，只看最局部
#### 2.2组合与复杂化

这是什么卷积核可以识别更高级的一些特征，如方向统计
以及将这些特征进行组合，来形成响应
如雨丝常呈“单一主方向 + 半透明 + 细长跨物体”的统计特征；这些层会把“随机、细长、单向”的响应聚合出来，为后面判别打地基
#### 2.3形成部件
不止研究独立的特征，开始将特征与其周围的“环境”联系
如学学习纹理组块、边界走向、结构一致性
而雨丝常跨越物体边界且与表面几何无依赖；真实条纹通常贴合物体表面
于是中层特征用比如是否跨越边界或者说是否与局部几何一致来判断是不是雨

#### 2.4上下文聚合与全局语义
学到什么： 物体/场景级语义、材质、布局（建筑、天空、人物等）
比如深层通过语义上下文判断“这条线是否合理地属于物体”（窗框、屋檐）还是“与场景无关的空气线段”（雨）
以及通过时域一致性，随物体运动的是真实纹理，不随之一起动、且闪烁的更像雨
***
## 问题二

>雨非常大时，密集的雨丝可能会完全遮挡住背景的一些细节（比如建筑的轮廓线）。在这种因干扰而难以分辨的情况下，模型还有可能复原出原来的物体吗？
***
所以说，虽然是叫“雨层”，但不是真的就是单纯的雨。
而是“雨对真实图像造成的全部差异“
所以对完全被雨遮挡的情况，雨层还要承担“复原”的功能
具体来说就是靠图像先验和语义推断
### 1.图像先验
“先验”其实就是经验知识——网络从数据中学到的统计规律
这些统计规律可以分为两种
一种是提前设置的，如在总的损失函数中加入的损失，来保证图片的平滑，连续等。这些规律没有语义，只是数据的统计特征
第二种是模型本身学习到的分布特征
### 2.语义推断
“语义推断”是比图像先验更高层的能力
网络不仅知道“像素怎么分布”，还知道“这是哪类物体”，因此能按语义补全
#### 2.1语义的形成
浅层：看到局部纹理（雨丝、边缘）；
中层：看到形状轮廓（建筑边界、车窗框）；
深层：理解语义结构（“这是楼、这是天空、这是路”）
#### 2.2帮助复原
![alt text](<img/截屏2025-10-10 15.51.54.png>)


去雨网络之所以能区分雨丝与纹理，是因为它学习到了雨丝在方向性、透明性与上下文一致性上的统计差异；
而当大雨导致背景信息完全缺失时，网络的‘复原’实质上是一种基于先验的语义重建，而非真实信号恢复
