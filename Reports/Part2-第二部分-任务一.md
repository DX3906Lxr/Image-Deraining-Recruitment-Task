# 问题一 
## 这里仍然是使用 L1 范数，对输出图像进行逐像素处理，仅仅是多使用了一个预训练模型，为什么 LPIPS 能够更好地衡量感知差异呢
在 PSNR / L1 / L2 这些传统指标中，我们直接在像素上比较     
也就是说，如果两张图的像素值稍有偏移（哪怕只是亮度差一点、物体移动一点），L1 就会判定为“差异很大”     
这种比较非常敏感于局部变化，但不符合人眼的感知规律      
LPIPS它仍然计算L1，但不在原图上计算，而是在特征空间上    
具体做法是：     
把两张图（真实图 x 和预测图 y）输入一个 预训练好的网络（如 VGG / AlexNet）    
提取出不同层的特征图，对每一层特征图计算 L1 距离，再把多层的距离加权求和    
当在这些特征上计算差距时：    
模型不会被像素的微小位移或亮度差扰动   
它更关注“语义结构是否一致”   
比如，一只猫的耳朵位置、毛发纹理等   
这更接近人眼的主观感知   
因此，LPIPS 更能反映“人觉得像不像”，而不仅是“数值上接不接近”   

## 预训练模型的作用
其实在做赛博画师的时候就已经用到了，预训练模型了，那里的作用和这里的作用是一样的，都是把预训练模型当作提取图像的感知特征表示的工具

## 代码实现
![alt text](<截屏2025-10-15 15.44.06.png>)
然后，main文件里的形参，好像本身就已经调好了吧